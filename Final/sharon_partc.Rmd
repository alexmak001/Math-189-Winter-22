---
title: "finalalex"
output: pdf_document
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(MASS)
```

## Question 1

Loading data
```{r}
train = read.table("spam-train.txt",header=FALSE, sep=",")
head(train)
```

```{r}
test = read.table("spam-test.txt",header=FALSE, sep=",")
head(test)
```
# Standardizing

Standardizing Train Data
```{r}
train_Standardized = data.frame(scale(train))
train_Standardized$V58 = train$V58
train_Standardized
```

Standardizing Test Data
```{r}
test_Standardized = data.frame(scale(test))
test_Standardized$V58 = test$V58
head(test_Standardized)
```

# A) Visualizing Standardized columns

Training Standardized Spam Data V$58 == 1
```{r}
spamStandTrain = train_Standardized[train_Standardized$V58 == 1,]
hist(spamStandTrain$V53,main="Number of times the Charater $ Appears", xlab="$ Character  Appearance")
```
Training Standardized Not Spam Data V$58 == 0
```{r}
NotspamStandTrain = train_Standardized[train_Standardized$V58 == 0,]
hist(NotspamStandTrain$V53,main="Number of times the Charater $ Appears", xlab="$ Character  Appearance")
```
# Log Transformation

Log Transformation on Train Data

```{r}
train_Log = data.frame(log(train+1))
train_Log$V58 = train$V58
head(train_Log)
```

Log Transformation on Test Data

```{r}
test_Log = data.frame(log(test+1))
test_Log$V58 = test$V58
head(test_Log)
```
# Visualizing Log Transformation
0 = Not Spam, 1 = Spam
```{r}
plot(train_Log$V56, train_Log$V57, col=factor(train_Log$V58),xlab="Log of length of the longest uninterrupted
sequence of capital letters", ylab="Log of sum of the lengths of uninterrupted
sequences of capital letters",main="Log of Longest Capital Letters vs. Sum of number of capital letters")
legend("bottomright",
       legend = levels(factor(train_Log$V58)),
       pch = 19,
       col = factor(levels(factor(train_Log$V58))))
```



# Discretize Transformation

Discretize Transformation on Train Data

```{r}
train_Discretize = data.frame(train>0)
train_Discretize$V58 = train$V58
train_Discretize = train_Discretize*1
head(train_Discretize)
```

Discretize Transformation on Test Data

```{r}
test_Discretize = data.frame(test>0)
test_Discretize$V58 = test$V58
test_Discretize = test_Discretize*1
head(test_Discretize)
```

# Visualization of Discretized Transformed Data
First five columns are if the words "make", "address", "all", "3d", "our" are present in the email.
```{r}
discLabels = c("make", "address", "all", "3d", "our")
means = c(mean(train_Discretize$V1),mean(train_Discretize$V2),mean(train_Discretize$V3),mean(train_Discretize$V4),mean(train_Discretize$V5))

barplot(means, main="Ratio of a word being present in all of the training emails",names.arg = discLabels,
   xlab="Word")
```

# B) Logistic Regression and Significance of Features

Standardized data 
```{r}
stan_lr <- glm(V58~., data=train_Standardized)
lr_testPred <- predict(stan_lr, test_Standardized)
lr_testPred <- ifelse(lr_testPred > 0.5, 1, 0)
lr_trainPred <- predict(stan_lr, train_Standardized)
lr_trainPred <- ifelse(lr_trainPred > 0.5, 1, 0)
lr_testError = mean(lr_testPred!=test_Standardized$V58)
lr_trainError = mean(lr_trainPred!=train_Standardized$V58)
lr_testError
lr_trainError

```

Log transformed data 
```{r}
log_lr <- glm(V58~., data=train_Log)
lr_logTestPred <- predict(log_lr, test_Log)
lr_logTestPred <- ifelse(lr_logTestPred > 0.5, 1, 0)
lr_logTrainPred <- predict(log_lr, train_Log)
lr_logTrainPred <- ifelse(lr_logTrainPred > 0.5, 1, 0)
lr_logTestError = mean(lr_logTestPred!=test_Log$V58)
lr_logTrainError = mean(lr_logTrainPred!=train_Log$V58)
lr_logTestError
lr_logTrainError
```

Discretized data 
```{r}
dis_lr <- glm(V58~., data=train_Discretize)
lr_disTestPred <- predict(dis_lr, test_Discretize)
lr_disTestPred <- ifelse(lr_disTestPred > 0.5, 1, 0)
lr_disTestError = mean(lr_disTestPred!=test_Discretize$V58)

lr_disTrainPred <- predict(dis_lr, train_Discretize)
lr_disTrainPred <- ifelse(lr_disTrainPred > 0.5, 1, 0)
lr_disTrainError  = mean (lr_disTrainPred!=train_Discretize$V58)

lr_disTestError
lr_disTrainError
```

Significance of features 
we can assess the variables' significance by looking at the t-values from the summary like a multiple testing problems with alpha equals 0.1. The variables that allow us to reject the null hypothesis are the significant variables. 
```{r}
stan_tval = coef(summary(stan_lr))[, 't value']
log_tval = coef(summary(log_lr))[, 't value']
dis_tval = coef(summary(dis_lr))[, 't value']

c_val = qt(0.95, df=99)
rej_stan = abs(stan_tval) >= c_val
rej_stanIdx = which(rej_stan==1)

rej_log = abs(log_tval) >= c_val
rej_logIdx = which(rej_log==1)

rej_dis = abs(dis_tval) >= c_val
rej_disIdx = which(rej_dis==1)

rej_stanIdx
rej_logIdx
rej_disIdx
```
These variables listed above are statistically significant from both the logistic regression model on standardized data and log transformed data. 

# C) LDA and QDA 

LDA on the standardized data 
```{r}
stan_model <- lda(V58~., data=train_Standardized)
stan_predictions <- predict(stan_model, test_Standardized)
stan_trainPred <- predict(stan_model, train_Standardized)
stan_class = stan_predictions$class
stan_true_val = test_Standardized$V58
stan_test_error = mean(stan_class!=stan_true_val)
stan_train_error = mean(stan_trainPred$class!=train_Standardized$V58)
stan_test_error
stan_train_error
```

LDA on the log transformed data 
```{r}
log_model <- lda(V58~., data=train_Log)
log_predictions <- predict(log_model, test_Log)
log_trainPred <- predict(log_model, train_Log)
log_class = log_predictions$class
log_true_val = test_Log$V58
log_test_error = mean(log_class!=log_true_val)
log_train_error = mean(log_trainPred$class!=train_Log$V58)
log_test_error
log_train_error
```

QDA on the standardized data 
```{r}
stan_qda <- qda(V58~., data=train_Standardized)
stan_qdaPred <- predict(stan_qda, test_Standardized)
stan_qdaTrainPred <- predict(stan_qda, train_Standardized)
stan_qdaClass = stan_qdaPred$class
stan_qdaTrue = test_Standardized$V58
stan_qdaTest = mean(stan_qdaClass != stan_qdaTrue)
stan_qdaTrainError = mean(stan_qdaTrainPred$class!=train_Standardized$V58)
stan_qdaTest
stan_qdaTrainError
```

QDA on the transformed data 
```{r}
log_qda = qda(V58~., data=train_Log)
log_qdaPred = predict(log_qda, test_Log)
log_qdaTrainPred = predict(log_qda, train_Log)
log_qdaTest = mean(log_qdaPred$class != test_Log$V58)
log_qdaTrainError = mean(log_qdaTrainPred$class!=train_Log$V58)
log_qdaTest
log_qdaTrainError
```

# Error Rate Table

Error rates in a table 
```{r}
tab <- matrix(c(stan_test_error,stan_qdaTest,log_test_error,
                log_qdaTest,lr_testError,lr_logTestError,
                stan_train_error,stan_qdaTrainError,
                log_train_error,log_qdaTrainError,
                lr_trainEror,lr_logTrainError), nrow=6, ncol=2)
colnames(tab) <- c('Test Error Rate', 'Train Error Rate')
rownames(tab) <- c('LDA on Standardized Data', 
                   'QDA on Standardized Data', 
                   'LDA on Log Transformed Data',
                   'QDA on Log Transformed Data', 
                   'Logistic Regression on Standardized Data',
                   'Logistic Regression on Log Transformed Data')
tab <- as.table(tab)
tab
```
Comment:  

# Classifier Design



