---
title: "hw7alex"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
install.packages("ggplot2")
install.packages("latex2exp")
library(ggplot2)
library(latex2exp)
```

## Question #1a

```{r cars}
x1 <- -10:10
x2 <- 3*x1 + 1

plot(x1, x2, type = "l", col = "blue")
text(c(0), c(-20), "Greater than 0", col = "blue")
text(c(0), c(20), "Less than 0", col = "blue")
```
## Question #1b

```{r cars}
x1 <- -10:10
x2 <- (-1/2)*x1 + 1

plot(x1, x2, type = "l", col = "blue")
text(c(0), c(3), "Greater than 0", col = "blue")
text(c(0), c(-2), "Less than 0", col = "blue")
```
## Question #3A
```{r cars}
train = read.csv("SVM_train.csv")
head(train)
```
```{r cars}
library(ggplot2)
ggplot(data=train, aes(x=x.1, y=x.2, color=y))+ geom_point()
```
The class labeled 2 is mostly centered around 0,0 and the other class, 1, is spread out on the upper right and bottom left side of the other class. The two classes are somewhat visually separable, but not perfectly separable: there are points that are almost on top of each othe and would require over fitting to perfectly predict. The decision boundry will definitely not be linear, and closer to a circle.


