train = train[,col]
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit, train[,col], type="binary")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit, train[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit, train[,col], type="class")
p_train
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit, train[,col], type="class")
print(p_train)
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
p <- predict(svmfit, iris_test[,col], type="class")
plot(p)
p <- predict(svmfit, iris_test[,col], type="class")
print(p)
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = sapply(train[,col], as.character)
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .1, scale = FALSE)
plot(iris)
iris
iris
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = sapply(train[,col], as.character)
train
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .1, scale = FALSE)
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train$y <- sapply(train$y, as.character)
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[, col]
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train = read.csv("SVM_train.csv")
head(train)
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train[,3] <- sapply(train[,3], as.character)
train
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .1, scale = FALSE)
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train[,3] <- sapply(train[,3], as.factor)
train
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit, train[,col], type="class")
print(p_train)
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train[,3] <- sapply(train[,3], as.factor)
train
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit, train[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train[,3] <- sapply(train[,3], as.factor)
train
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .001, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit, train[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
library("ggplot2")
test = read.csv("SVM_test.csv")
col<-c("x.1", "x.2", "y")
test = test[,col]
test[,3] <- sapply(test[,3], as.factor)
p_test <- predict(svmfit, test[,col], type="class")
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
library("ggplot2")
svmfit <- svm(y ~., data = train, kernel = "radial", cost = .1, gamma = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "radial",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
summary(tuned)
tuned <- tune(svm, y ~., data = train, kernel = "radial",
ranges = list(gamma=c(0.001,0.01,.1,1,10,100)))
summary(tuned)
svmfit <- svm(y ~., data = train, kernel = "radial", cost = 1, gamma = 1, scale = FALSE)
p_train <- predict(svmfit, train[,col], type="class")
p_test <- predict(svmfit, test[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
library(dplyr)
library(stargazer)
library(caret)
loan <- read.csv("https://www.dropbox.com/s/89g1yyhwpcqwjn9/lending_club_cleaned.csv?raw=1")
#loan <- read.csv("C:/Users/dvorakt/Google Drive/business analytics/labs/lab9/lending_club_cleaned.csv")
summary(loan)
loan$good = ifelse(loan$good == "good", 1, 0)
loan$fico = as.numeric(loan$fico)
loan$loan_amnt = as.numeric(loan$loan_amnt)
set.seed(189)
sample <- sample(1:nrow(loan), 40000)
train <- loan[sample,]
test <- loan[-sample,]
logit1 <- glm(good ~ fico, data = train, family = "binomial")
summary(logit1)
pred_prob_1 = predict(logit1, test, type = "response")
pred_1 = ifelse(pred_prob_1 > 0.8, 1, 0)
logit2 <- glm(good ~ fico + loan_amnt, data = train, family = "binomial")
summary(logit2)
pred_prob_2 = predict(logit2, test, type = "response")
pred_2 = ifelse(pred_prob_2 > 0.8, 1, 0)
library(pROC)
roc_1 <- roc(test$good ~ pred_prob_1, plot = T, print.auc = T) #with all possible cutoff!
roc_2 <- roc(test$good, pred_prob_2, plot = T, print.auc = T)
library("ggplot2")
svmfit <- svm(y ~., data = train, kernel = "radial", cost = .1, gamma = .1, scale = FALSE)
train = read.csv("SVM_train.csv")
head(train)
library(ggplot2)
ggplot(data=train, aes(x=x.1, y=x.2, color=y))+ geom_point()
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train[,3] <- sapply(train[,3], as.factor)
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .001, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit, train[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
library("ggplot2")
test = read.csv("SVM_test.csv")
col<-c("x.1", "x.2", "y")
test = test[,col]
test[,3] <- sapply(test[,3], as.factor)
p_test <- predict(svmfit, test[,col], type="class")
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
library("ggplot2")
svmfit <- svm(y ~., data = train, kernel = "radial", cost = .1, gamma = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "radial",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
summary(tuned)
tuned <- tune(svm, y ~., data = train, kernel = "radial",
ranges = list(gamma=c(0.001,0.01,.1,1,10,100)))
summary(tuned)
svmfit <- svm(y ~., data = train, kernel = "radial", cost = 100, gamma = 1, scale = FALSE)
p_train <- predict(svmfit, train[,col], type="class")
p_test <- predict(svmfit, test[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
library("ggplot2")
svmfit <- svm(y ~., data = train, kernel = "radial", cost = 10, gamma = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "radial",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
summary(tuned)
tuned <- tune(svm, y ~., data = train, kernel = "radial",
ranges = list(gamma=c(0.001,0.01,.1,1,10,100)))
summary(tuned)
svmfit <- svm(y ~., data = train, kernel = "radial", cost = 10, gamma = .1, scale = FALSE)
p_train <- predict(svmfit, train[,col], type="class")
p_test <- predict(svmfit, test[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
library("ggplot2")
svmfit <- svm(y ~., data = train, kernel = "radial", cost = .1, gamma = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "radial",
ranges = list(cost=c(0.001,0.01,.1,1,10,100), gamma=c(0.001,0.01,.1,1,10,100)))
summary(tuned)
svmfit <- svm(y ~., data = train, kernel = "radial", cost = 10, gamma = .1, scale = FALSE)
p_train <- predict(svmfit, train[,col], type="class")
p_test <- predict(svmfit, test[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
library("ggplot2")
svmfit <- svm(y ~., data = train, kernel = "radial", cost = .1, gamma = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "radial",
ranges = list(cost=c(0.001,0.01,.1,1,10,100), gamma=c(0.001,0.01,.1,1,10,100)))
summary(tuned)
svmfit <- svm(y ~., data = train, kernel = "radial", cost = 0.1, gamma = 1, scale = FALSE)
p_train <- predict(svmfit, train[,col], type="class")
p_test <- predict(svmfit, test[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
library("ggplot2")
svmfit <- svm(y ~., data = train, kernel = "radial", cost = .1, gamma = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "radial",
ranges = list(cost=c(0.001,0.01,.1,1,10,100), gamma=c(0.001,0.01,.1,1,10,100)))
summary(tuned)
svmfit <- svm(y ~., data = train, kernel = "radial", cost = 0.1, gamma = 1, scale = FALSE)
p_train <- predict(svmfit, train[,col], type="class")
p_test <- predict(svmfit, test[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train[,3] <- sapply(train[,3], as.factor)
svmfit <- svm(y ~., data = train, kernel = "linear", cost = .001, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit, train[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
library("ggplot2")
test = read.csv("SVM_test.csv")
col<-c("x.1", "x.2", "y")
test = test[,col]
test[,3] <- sapply(test[,3], as.factor)
p_test <- predict(svmfit, test[,col], type="class")
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
library(dplyr)
library(stargazer)
library(caret)
train
logit2 <- glm(good ~ fico + loan_amnt, data = train, family = "binomial")
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train[,3] <- sapply(train[,3], as.factor)
svmfit_1 <- svm(y ~., data = train, kernel = "linear", cost = .001, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit_1, train[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
library("ggplot2")
test = read.csv("SVM_test.csv")
col<-c("x.1", "x.2", "y")
test = test[,col]
test[,3] <- sapply(test[,3], as.factor)
p_test <- predict(svmfit_1, test[,col], type="class")
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
library("ggplot2")
svmfit <- svm(y ~., data = train, kernel = "radial", cost = .1, gamma = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "radial",
ranges = list(cost=c(0.001,0.01,.1,1,10,100), gamma=c(0.001,0.01,.1,1,10,100)))
summary(tuned)
svmfit_2 <- svm(y ~., data = train, kernel = "radial", cost = 0.1, gamma = 1, scale = FALSE)
p_train <- predict(svmfit_2, train[,col], type="class")
p_test <- predict(svmfit_2, test[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
pred_1_train = predict(svmfit_1, train[,col], type="class")
pred_1_test = predict(svmfit_1, test[,col], type="class")
pred_2_train = predict(svmfit_2, train[,col], type="class")
pred_2_test = predict(svmfit_2, test[,col], type="class")
library(pROC)
roc_1 <- roc(train$y ~ pred_1_train, plot = T, print.auc = T) #with all possible cutoff!
pred_1_train = predict(svmfit_1, train[,col], type="class")
pred_1_test = predict(svmfit_1, test[,col], type="class")
pred_2_train = predict(svmfit_2, train[,col], type="class")
pred_2_test = predict(svmfit_2, test[,col], type="class")
library(pROC)
roc_1 <- roc(train$y, pred_1_train, plot = T, print.auc = T) #with all possible cutoff!
roc_1 <- roc(test$good ~ pred_prob_1, plot = T, print.auc = T) #with all possible cutoff!
roc_2 <- roc(test$good, pred_prob_2, plot = T, print.auc = T)
library(dplyr)
library(stargazer)
library(caret)
loan <- read.csv("https://www.dropbox.com/s/89g1yyhwpcqwjn9/lending_club_cleaned.csv?raw=1")
#loan <- read.csv("C:/Users/dvorakt/Google Drive/business analytics/labs/lab9/lending_club_cleaned.csv")
summary(loan)
loan$good = ifelse(loan$good == "good", 1, 0)
loan$fico = as.numeric(loan$fico)
loan$loan_amnt = as.numeric(loan$loan_amnt)
set.seed(189)
sample <- sample(1:nrow(loan), 40000)
train <- loan[sample,]
test <- loan[-sample,]
logit1 <- glm(good ~ fico, data = train, family = "binomial")
summary(logit1)
pred_prob_1 = predict(logit1, test, type = "response")
pred_1 = ifelse(pred_prob_1 > 0.8, 1, 0)
logit2 <- glm(good ~ fico + loan_amnt, data = train, family = "binomial")
summary(logit2)
pred_prob_2 = predict(logit2, test, type = "response")
pred_2 = ifelse(pred_prob_2 > 0.8, 1, 0)
library(pROC)
roc_1 <- roc(test$good ~ pred_prob_1, plot = T, print.auc = T) #with all possible cutoff!
roc_2 <- roc(test$good, pred_prob_2, plot = T, print.auc = T)
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train = read.csv("SVM_train.csv")
head(train)
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train[,3] <- sapply(train[,3], as.factor)
svmfit_1 <- svm(y ~., data = train, kernel = "linear", cost = .1, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit_1, train[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
#install.packages("e1071")
library("e1071")
library("ggplot2")
col<-c("x.1", "x.2", "y")
train = train[,col]
train[,3] <- sapply(train[,3], as.factor)
svmfit_1 <- svm(y ~., data = train, kernel = "linear", cost = .001, scale = FALSE)
tuned <- tune(svm, y ~., data = train, kernel = "linear",
ranges = list(cost=c(0.001,0.01,.1,1,10,100)))
# Will show the optimal cost parameter
summary(tuned)
p_train <- predict(svmfit_1, train[,col], type="class")
ggplot(data=train, aes(x=x.1, y=x.2, color=p_train))+ geom_point()
pred_1_train = predict(svmfit_1, train[,col], type="class")
pred_1_test = predict(svmfit_1, test[,col], type="class")
library("ggplot2")
test = read.csv("SVM_test.csv")
col<-c("x.1", "x.2", "y")
test = test[,col]
test[,3] <- sapply(test[,3], as.factor)
p_test <- predict(svmfit_1, test[,col], type="class")
ggplot(data=test, aes(x=x.1, y=x.2, color=p_test))+ geom_point()
pred_1_train = predict(svmfit_1, train[,col], type="class")
pred_1_test = predict(svmfit_1, test[,col], type="class")
pred_2_train = predict(svmfit_2, train[,col], type="class")
pred_2_test = predict(svmfit_2, test[,col], type="class")
rocplot =function (pred , truth , ...){
predob = prediction(pred , truth )
perf=performance(predob , "fpr", "tpr")
plot(perf ,...)}
# Prepare the training and testing predictions for ROC curve
# optimal cost for linear kernel is C=0.5
linear.opt=svm(y~., train, kernel ="linear", cost=0.001, decision.values =TRUE)
linear.train=attributes(predict (linear.opt, train, decision.values =TRUE))$decision.values
linear.test=attributes(predict (linear.opt, test, decision.values =TRUE))$decision.values
# Prepare the training and testing predictions for ROC curve
# optimal cost for gaussian kernel is gamma=0.5, C=1
gaussian.opt=svm(y~., data.train, kernel ="radial", gamma=0.1, cost=1, decision.values =TRUE)
pred_1_train = predict(svmfit_1, train[,col], type="class")
pred_1_test = predict(svmfit_1, test[,col], type="class")
pred_2_train = predict(svmfit_2, train[,col], type="class")
pred_2_test = predict(svmfit_2, test[,col], type="class")
rocplot =function (pred , truth , ...){
predob = prediction(pred , truth )
perf=performance(predob , "fpr", "tpr")
plot(perf ,...)}
# Prepare the training and testing predictions for ROC curve
# optimal cost for linear kernel is C=0.5
linear.opt=svm(y~., train, kernel ="linear", cost=0.001, decision.values =TRUE)
linear.train=attributes(predict (linear.opt, train, decision.values =TRUE))$decision.values
linear.test=attributes(predict (linear.opt, test, decision.values =TRUE))$decision.values
# Prepare the training and testing predictions for ROC curve
# optimal cost for gaussian kernel is gamma=0.5, C=1
gaussian.opt=svm(y~., train, kernel ="radial", gamma=0.1, cost=1, decision.values =TRUE)
gaussian.train=attributes(predict (gaussian.opt, train, decision.values =TRUE))$decision.values
gaussian.test=attributes(predict (gaussian.opt, test, decision.values =TRUE))$decision.values
library(pROC)
rocplot(linear.train, train[,"y"], main="ROC for Training Set", col="red")
pred_1_train = predict(svmfit_1, train[,col], type="class")
pred_1_test = predict(svmfit_1, test[,col], type="class")
pred_2_train = predict(svmfit_2, train[,col], type="class")
pred_2_test = predict(svmfit_2, test[,col], type="class")
rocplot =function (pred , truth , ...){
predob = prediction(pred , truth )
perf=performance(predob , "fpr", "tpr")
plot(perf ,...)}
# Prepare the training and testing predictions for ROC curve
# optimal cost for linear kernel is C=0.5
linear.opt=svm(y~., train, kernel ="linear", cost=0.001, decision.values =TRUE)
linear.train=attributes(predict (linear.opt, train, decision.values =TRUE))$decision.values
linear.test=attributes(predict (linear.opt, test, decision.values =TRUE))$decision.values
# Prepare the training and testing predictions for ROC curve
# optimal cost for gaussian kernel is gamma=0.5, C=1
gaussian.opt=svm(y~., train, kernel ="radial", gamma=0.1, cost=1, decision.values =TRUE)
gaussian.train=attributes(predict (gaussian.opt, train, decision.values =TRUE))$decision.values
gaussian.test=attributes(predict (gaussian.opt, test, decision.values =TRUE))$decision.values
library(ROCR)
pred_1_train = predict(svmfit_1, train[,col], type="class")
pred_1_test = predict(svmfit_1, test[,col], type="class")
pred_2_train = predict(svmfit_2, train[,col], type="class")
pred_2_test = predict(svmfit_2, test[,col], type="class")
rocplot =function (pred , truth , ...){
predob = prediction(pred , truth )
perf=performance(predob , "fpr", "tpr")
plot(perf ,...)}
# Prepare the training and testing predictions for ROC curve
# optimal cost for linear kernel is C=0.5
linear.opt=svm(y~., train, kernel ="linear", cost=0.001, decision.values =TRUE)
linear.train=attributes(predict (linear.opt, train, decision.values =TRUE))$decision.values
linear.test=attributes(predict (linear.opt, test, decision.values =TRUE))$decision.values
# Prepare the training and testing predictions for ROC curve
# optimal cost for gaussian kernel is gamma=0.5, C=1
gaussian.opt=svm(y~., train, kernel ="radial", gamma=0.1, cost=1, decision.values =TRUE)
gaussian.train=attributes(predict (gaussian.opt, train, decision.values =TRUE))$decision.values
gaussian.test=attributes(predict (gaussian.opt, test, decision.values =TRUE))$decision.values
install.packages("ROCR")
library(ROCR)
rocplot(linear.train, train[,"y"], main="ROC for Training Set", col="red")
rocplot(gaussian.train, train[,"y"], add=T, col="blue")
legend("bottomright", legend=c("Linear", "Gaussian"),
col=c("red", "blue"), lty=c(1,1,1), cex=1.5)
#dev.off()
# Plot ROC curves for testing set
#png(file = "ROC_testing.png", width=640, height=480)
rocplot(linear.test, test[,"y"], main="ROC for Training Set", col="red")
rocplot(gaussian.test, test[,"y"], add=T, col="blue")
legend("bottomright", legend=c("Linear", "Gaussian"),
col=c("red", "blue"), lty=c(1,1,1), cex=1.5)
pred_1_train = predict(svmfit_1, train[,col], type="class")
pred_1_test = predict(svmfit_1, test[,col], type="class")
pred_2_train = predict(svmfit_2, train[,col], type="class")
pred_2_test = predict(svmfit_2, test[,col], type="class")
rocplot =function (pred , truth , ...){
predob = prediction(pred , truth )
perf=performance(predob , "fpr", "tpr")
plot(perf ,...)}
# Prepare the training and testing predictions for ROC curve
# optimal cost for linear kernel is C=0.5
linear.opt=svm(y~., train, kernel ="linear", cost=0.001, decision.values =TRUE)
linear.train=attributes(predict (linear.opt, train, decision.values =TRUE))$decision.values
linear.test=attributes(predict (linear.opt, test, decision.values =TRUE))$decision.values
# Prepare the training and testing predictions for ROC curve
# optimal cost for gaussian kernel is gamma=0.5, C=1
gaussian.opt=svm(y~., train, kernel ="radial", gamma=0.1, cost=1, decision.values =TRUE)
gaussian.train=attributes(predict (gaussian.opt, train, decision.values =TRUE))$decision.values
gaussian.test=attributes(predict (gaussian.opt, test, decision.values =TRUE))$decision.values
#install.packages("ROCR")
library(ROCR)
rocplot(linear.train, train[,"y"], main="ROC for Training Set", col="red")
rocplot(gaussian.train, train[,"y"], add=T, col="blue")
legend("bottomright", legend=c("Linear", "Gaussian"),
col=c("red", "blue"), lty=c(1,1), cex=1.5)
#dev.off()
# Plot ROC curves for testing set
#png(file = "ROC_testing.png", width=640, height=480)
rocplot(linear.test, test[,"y"], main="ROC for Testing Set", col="red")
rocplot(gaussian.test, test[,"y"], add=T, col="blue")
legend("bottomright", legend=c("Linear", "Gaussian"),
col=c("red", "blue"), lty=c(1,1), cex=1.5)
